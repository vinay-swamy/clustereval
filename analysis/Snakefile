import numpy as np


rule all:
    input:
        clustering = expand('cluster_out/ds-{countMat}_alg-{alg}_knn-{k}_.csv.gz', k=list(range(5,101,5)),
                                countMat = ['sanes_amacrine','pbmc', 'pbmc_sim_20groups-V1', 'pbmc_sim_10groups-V1'], 
                                alg = ['louvain', 'leiden']),
        metrics = expand('cluster_metrics/ds-{countMat}_alg-{alg}_knn-{k}_.csv.gz', k=list(range(5,101,5)),
                                countMat = ['sanes_amacrine','pbmc'], 
                                alg = ['louvain', 'leiden'])

rule make_count_matrices:
    output:
        'data/count_mats/sanes_amacrine_preproccessed.csv.gz',
        'data/count_mats/pbmc_preproccessed.csv.gz',
    shell:
        '''

        wget https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz
        wget https://ftp.ncbi.nlm.nih.gov/geo/series/GSE149nnn/GSE149715/suppl/GSE149715%5FMouseAC%5Fcount%5Fmatrix%2Ecsv%2Egz
        tar -xzf pbmc3k_filtered_gene_bc_matrices.tar.gz
        module load R/4.0.3
        Rscript scripts/make_raw_data.R
        rm pbmc3k_filtered_gene_bc_matrices.tar.gz
        rm filtered_gene_bc_matrices/ -rf
        rm GSE149715_MouseAC_count_matrix.csv.gz

        '''


rule run_parameter_exp_clustering:
    input: 
        mat = 'data/count_mats/{countMat}_preproccessed.csv.gz'
    output:
        clustering = 'cluster_out/ds-{countMat}_alg-{alg}_knn-{k}_.csv.gz',
        metrics = 'cluster_metrics/ds-{countMat}_alg-{alg}_knn-{k}_.csv.gz'

    run:
        import clustereval as ce
        import pandas as pd 
        
        metrics,labels, perturbations = ce.cluster.run_full_experiment(reduction = pd.read_csv(input.mat), 
                                         alg = wildcards.alg, 
                                         k=int(wildcards.k),
                                         n_perturbations=100,
                                         edge_permut_frac=.05,
                                         min_cluster_size=25,
                                         experiment_name=f'experiment2-{wildcards.countMat}-{str(wildcards.k)}-{wildcards.alg}'
                                         )
        
        labels.to_csv(output.clustering)
        metrics.to_csv(output.metrics)



# rule calculate_parameter_exp_metrics:
#     input: 
#         expand('par_exp_out/{{countMat}}-exp_alg-{{alg}}_res-{res}_knn-{n}_.csv.gz', 
#                 res = [.2,.3, .4, .5, .6, .7, .8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0], n=list(range(5,100,5)))
#     output:
#         results = 'par_exp_metrics/{countMat}-exp_alg-{alg}.pickle'
#     params:
#         glob_string= lambda wildcards: f'par_exp_out/{wildcards.countMat}-exp_alg-{wildcards.alg}*_.csv.gz'
#     run:
#         import clustereval as ce
#         import numpy as np 
#         import pandas as pd
#         import pickle
#         exp_results = ce.calc_metrics.pairwise_metric_calculation_fromdisk(params.glob_string, 96)
#         with open(output.results, 'wb+') as outfile:
#             exp_results = [{'exp_param': i.exp_param, 
#                             'cluster_ids':i.cluster_ids, 
#                             'stability_scores': i.stability_scores, 
#                             'purity_scores': i.purity_scores} for i in exp_results  ]
#             pickle.dump(exp_results, outfile)
        
